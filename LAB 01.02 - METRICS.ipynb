{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the following cell to login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint https://m5knaekxo6.execute-api.us-west-2.amazonaws.com/dev-v0001/rlxmooc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>See <a href='https://m5knaekxo6.execute-api.us-west-2.amazonaws.com/dev-v0001/rlxmooc/web/login' target='_blank'>my courses and progress</a></h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/20201.ai4eng/master/init.py\n",
    "import init, inspect; init.init(force_download=False); init.get_weblink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username: kevin.martinez@udea.edu.co\n",
      "password: ········\n"
     ]
    }
   ],
   "source": [
    "from local.lib.rlxmoocapi import submit, session\n",
    "student = session.Session(init.endpoint).login( course_id=init.course_id, \n",
    "                                                session_id=\"UDEA\", \n",
    "                                                lab_id=\"L01.02\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General remark\n",
    "\n",
    "You do not need to use Python to solve the problems in this notebook, you can use any tool of your choice (Excel, etc.), including **pen and paper**. But\n",
    "\n",
    "### If you want to try out in Python\n",
    "\n",
    "- `numpy` is the Python library used for vectors\n",
    "- there are operations that take a vector and produce another vector (i.e. `np.log`)\n",
    "- there are operations that take a vector and procude a number (i.e. `np.mean`)\n",
    "- there are operations that take two vectors and produce a number (see the **HINTs** below)\n",
    "- etc.\n",
    "\n",
    "For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = np.array([1,2,3,4])\n",
    "\n",
    "# the log of each element of the vector\n",
    "print ( \"the log   =\", np.log(v1)  )\n",
    "\n",
    "# the mean of all elements of the vector\n",
    "print ( \"the mean  =\",  np.mean(v1)  )\n",
    "\n",
    "# multiply all elements of a vector with a scalar\n",
    "print (\"times two =\", 2*v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can always check the type of any variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2.0\n",
    "type(v1), type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 01. Accuracy\n",
    "\n",
    "Compute the percentage of correct predictions **accuracy** (see [here](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Definitions)) for the following model output (`predicted`) and ground truth (`actual`).\n",
    "\n",
    "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
    "\n",
    "**CHALLENGE**: use Python with [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "\n",
    "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1\n",
      "predicted 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "t1_actual    = np.random.randint(2, size=20)\n",
    "t1_predicted = np.abs(t1_actual*(np.random.random(size=20)>(np.random.random()*.9+.05)).astype(int))\n",
    "print (\"actual   \", \", \".join([str(i) for i in t1_actual]))\n",
    "print (\"predicted\", \", \".join([str(i) for i in t1_predicted]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the value of your computation to the `accuracy` variable, **with three decimal places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(t1_actual, t1_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <b>task_01 submitted.</b> <b><font color=\"blue\">your grade is 5</font></b> \n",
       "                <p/><pre>----- grader message -------</pre><b>correct</b><pre>----------------------------</pre>\n",
       "                <p/><p/>\n",
       "                <div style=\"font-size:10px\"><b>SUBMISSION CODE</b> 6CBNdYTKjEiglZxIpjTsSMtZq5bvWcuhP/cIJp8VOZwWUtDI1//QE/2wmNOM7XgnfKcyhmCv7sTRjx6s6HpKSHkbt4+tdz4eTNKq1WhY3wJnCU8sQ3HGvtlwtq5+iR5EjmHrDxv2NILP4GM77mrzrg==</div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student.submit_task(globals(), task_id=\"task_01\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Sensitivity\n",
    "\n",
    "Compute the sensitivity metric [aka the _True Positive Rate_ or _Recall_ see [Sensitivity on Wikipedia](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)] for the following model output (`predicted`) and ground truth (`actual`)\n",
    "\n",
    "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
    "\n",
    "**Challenge**: Use Python [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "\n",
    "\n",
    "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1\n",
      "predicted 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "t2_predicted = np.random.randint(2, size=20)\n",
    "t2_actual = np.random.randint(2, size=20)\n",
    "t2_predicted[np.argwhere(t2_actual==1)[0][0]]=0\n",
    "print (\"actual   \", \", \".join([str(i) for i in t2_actual]))\n",
    "print (\"predicted\", \", \".join([str(i) for i in t2_predicted]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the value of your computation to the `tpr` variable **with three decimal places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "tpr = recall_score(t2_actual, t2_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <b>task_02 submitted.</b> <b><font color=\"blue\">your grade is 5</font></b> \n",
       "                <p/><pre>----- grader message -------</pre><b>correct</b><pre>----------------------------</pre>\n",
       "                <p/><p/>\n",
       "                <div style=\"font-size:10px\"><b>SUBMISSION CODE</b> TPgaZXUT8Vx89BGYZkp5dOkBADY/Hi6cKBBjHNHFhTVlqNV5y93comj/sB8yM4yFCCruFba6QStScclvYyAg2sKxJUb1JZREyfB9UwR8EluDqrG6mFwx7oZ1TYvEAHg7cgoxQl8slqUeqGeXHyWc1Q==</div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student.submit_task(globals(), task_id=\"task_02\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Evaluation in New York City Taxi Trip Duration Kaggle Competition\n",
    "\n",
    "Understand the data and the evaluation metric (**Root Mean Squared Logarithmic Error**, RMSLE) of the following Kaggle competition\n",
    "\n",
    "- https://www.kaggle.com/c/nyc-taxi-trip-duration/\n",
    "\n",
    "Observe that this competition is a **regression task** as we are measuring the difference in prediction with respect to the actual.\n",
    "\n",
    "For instance, the following model predictions and ground truth:\n",
    "\n",
    "    actual    [66 37 22]\n",
    "    predicted [79 51 67]\n",
    "    \n",
    "produce a **RMSLE** of 0.66 aprox.\n",
    "\n",
    "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
    "\n",
    "**Challenge**: For python use numpy function `np.log` or `np.log1p`\n",
    "\n",
    "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    [94 27 79 77 34 34 77 69 34 73 75 79 73 50 61]\n",
      "predicted [42 59 23 85 89 80 93 27 26 53 80 80 25 59 28]\n"
     ]
    }
   ],
   "source": [
    "t3_actual    = np.random.randint(80,size=15)+20\n",
    "t3_predicted = np.random.randint(80,size=15)+20\n",
    "print (\"actual   \", t3_actual)\n",
    "print (\"predicted\", t3_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the value of your computation to the `rmsle` variable **with three decimal places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6834926244300674"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle = np.sqrt((1/np.size(t3_actual)) * np.sum(((np.log1p(t3_actual)) - (np.log1p(t3_predicted)))**2))\n",
    "rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <b>task_03 submitted.</b> <b><font color=\"blue\">your grade is 5</font></b> \n",
       "                <p/><pre>----- grader message -------</pre><b>correct</b><pre>----------------------------</pre>\n",
       "                <p/><p/>\n",
       "                <div style=\"font-size:10px\"><b>SUBMISSION CODE</b> JhDcuhh+CkJjpyI3l4dAfcDeGy8VSXMDDzggibtKkp46I4lHauPaSKbzPgULokP6ngLPCCgbE07iwkfhI8VsHyy7rg1EfzMFDNIP99xCAy3XqHvDzV1GuWS7RYb4962IxI+5Jpxlvfu5qA0Z4L56jg==</div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student.submit_task(globals(), task_id=\"task_03\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Evaluation in Shelter Animal Outcomes Kaggle Competition\n",
    "\n",
    "Understand the data and the evaluation metric (**Multiclass Logaritmic Loss**, _logloss_) of the following Kaggle competition\n",
    "\n",
    "- https://www.kaggle.com/c/shelter-animal-outcomes/\n",
    "\n",
    "Observe that this competition is a **classification task with 5 classes** and, for each item, the model produces a probability for each class. Classes are numbered from 0 to 4.\n",
    "\n",
    "For instance, the following represents the model output for **three items**\n",
    "\n",
    "    [[0.17 0.27 0.03 0.31 0.21]\n",
    "     [0.09 0.44 0.02 0.15 0.3 ]\n",
    "     [0.26 0.18 0.25 0.2  0.11]]\n",
    "     \n",
    "Where the classes with gretest probability assigned by the model are \n",
    "\n",
    "- class 3 for the first item (with 0.31 probability) \n",
    "- class 1 for the second item (with 0.44 probability)\n",
    "- class 0 for the third item (with 0.26 probability)\n",
    "\n",
    "The class labels are expressed as a similar matrix, but with 0/1\n",
    "For instance, the ground truth for the corresponding three items above, could be:\n",
    "\n",
    "    [[0 0 0 1 0]\n",
    "     [0 0 1 0 0]\n",
    "     [1 0 0 0 0]]\n",
    "\n",
    "and will produce a **logloss** of approx 2.14\n",
    "\n",
    "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "[[0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]]\n",
      "\n",
      "predicted\n",
      "[[0.25 0.15 0.33 0.11 0.16]\n",
      " [0.29 0.15 0.26 0.1  0.21]\n",
      " [0.31 0.19 0.18 0.16 0.16]\n",
      " [0.23 0.18 0.23 0.12 0.25]\n",
      " [0.17 0.19 0.18 0.19 0.27]\n",
      " [0.27 0.14 0.21 0.21 0.16]\n",
      " [0.19 0.24 0.22 0.13 0.22]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t4_predicted = np.random.random(size=(7,5)).T+0.5\n",
    "t4_predicted = np.round((t4_predicted/np.sum(t4_predicted,axis=0)),2).T\n",
    "\n",
    "t4_actual = np.eye(5)[np.random.randint(5,size=len(t4_predicted))].astype(int)\n",
    "\n",
    "print (\"actual\")\n",
    "print (t4_actual)\n",
    "print (\"\\npredicted\")\n",
    "print (t4_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the value of your computation to the `logloss` variable **with three decimal places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6876690771687495"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "logloss = log_loss(t4_actual, t4_predicted)\n",
    "logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <b>task_04 submitted.</b> <b><font color=\"blue\">your grade is 5</font></b> \n",
       "                <p/><pre>----- grader message -------</pre><b>correct</b><pre>----------------------------</pre>\n",
       "                <p/><p/>\n",
       "                <div style=\"font-size:10px\"><b>SUBMISSION CODE</b> ZDm/DgZHcBMYGq7TiQMMkE9g5ipeSwJx97Yo5cHyEUOJFsEtNqC0MWag+Itlwb5KYuEZWerioL72yXCVBXJDcTfL8G2nS/sMT+W+ViE8XYYmDeipGSXHuFXINHqRLcrVGiQJ58+L8kR1bZWHsn7NLw==</div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student.submit_task(globals(), task_id=\"task_04\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
